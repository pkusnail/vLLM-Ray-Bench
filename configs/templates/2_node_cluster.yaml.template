# 2-node cluster configuration template
# Use case: 2 servers, each with 8 GPUs

cluster:
  name: "${CLUSTER_NAME}"
  max_concurrent_requests: 32

model:
  name: "${MODEL_NAME}"
  max_model_len: ${MAX_MODEL_LEN}
  trust_remote_code: true
  gpu_memory_utilization: ${GPU_MEMORY_UTILIZATION}
  swap_space: 8
  quantization: null

distributed:
  strategy: "auto"  # Will configure PP=2, TP=8

nodes:
  head:
    ip: "${HEAD_NODE_IP}"
    port: 6379
    dashboard_port: ${RAY_DASHBOARD_PORT}
    gpus: 8
    cpus: 32
    memory: "320GB"
    
  workers:
    - ip: "${WORKER_NODE_IP_1}"
      gpus: 8
      cpus: 32
      memory: "320GB"

service:
  host: "0.0.0.0"
  port: ${VLLM_API_PORT}
  max_num_seqs: 16

network:
  nccl:
    use_default: true

environment:
  python_path: "./venv/bin/python"
  ray_env_path: "./venv"
  working_directory: "$(pwd)"

security:
  ssh_user: "ubuntu"
  ssh_key_path: "~/.ssh/id_rsa"

monitoring:
  enable_metrics: true
  prometheus_port: 9090
  log_level: "INFO"